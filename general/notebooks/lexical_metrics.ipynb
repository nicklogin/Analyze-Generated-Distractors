{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4184b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "from collections import defaultdict\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5eb307d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEX_POS_TAGS = [\n",
    "    \"ADJ\", \"ADV\", \"NOUN\", \"PROPN\", \"VERB\"\n",
    "]\n",
    "\n",
    "def get_lex_features(\n",
    "    parsed_texts: list[list[dict]], exclude_punct: bool=True\n",
    ") -> dict[str, float]:\n",
    "    parsed_sents = [\n",
    "        sent for text in parsed_texts\n",
    "        for sent in text\n",
    "    ]\n",
    "\n",
    "    output = dict()\n",
    "\n",
    "    all_tokens = [token for sent in parsed_sents for token in sent]\n",
    "\n",
    "    if exclude_punct:\n",
    "        all_tokens = [\n",
    "            token for token in all_tokens if token[\"pos\"] != \"PUNCT\"\n",
    "        ]\n",
    "    lexical_tokens = [\n",
    "        token for token in all_tokens if token[\"pos\"] in LEX_POS_TAGS\n",
    "    ]\n",
    "    unique_tokens = set(\n",
    "        token[\"text\"] for token in all_tokens\n",
    "    )\n",
    "    unique_lemmas = set(\n",
    "        token[\"lemma\"] for token in all_tokens\n",
    "    )\n",
    "\n",
    "    # TTR (Type/token ratio)\n",
    "    if len(all_tokens):\n",
    "        output[\"TTR\"] = len(unique_tokens) / len(all_tokens)\n",
    "    else:\n",
    "        output[\"TTR\"] = 0.0\n",
    "\n",
    "    # LTR (Lemma/token ratio)\n",
    "    if len(all_tokens):\n",
    "        output[\"LTR\"] = len(unique_lemmas) / len(all_tokens)\n",
    "    else:\n",
    "        output[\"LTR\"] = 0.0\n",
    "\n",
    "    # LD (Lexical density, proportion of content words\n",
    "    # (nouns, verbs, adjectives, adverbs) against total words)\n",
    "    if len(all_tokens):\n",
    "        output[\"LD\"] = len(lexical_tokens) / len(all_tokens)\n",
    "    else:\n",
    "        output[\"LD\"] = 0.0\n",
    "\n",
    "    return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2c564f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_text_parse(\n",
    "    parse_result: dict\n",
    ") -> list[list[dict[str, Union[str, int]]]]:\n",
    "    parsed_sents = []\n",
    "\n",
    "    for sent_border in parse_result[\"sents\"]:\n",
    "        parsed_sent = []\n",
    "        sent_border_a = sent_border[\"start\"]\n",
    "        sent_border_b = sent_border[\"end\"]\n",
    "        for token in parse_result[\"tokens\"]:\n",
    "            if (\n",
    "                token[\"start\"] >= sent_border_a\n",
    "            ) and (\n",
    "                token[\"end\"] <= sent_border_b\n",
    "            ):\n",
    "                parsed_sent.append(token)\n",
    "        parsed_sents.append(parsed_sent)\n",
    "\n",
    "    # Пересчитаем индексы токенов и их вершин, так чтобы\n",
    "    # нумерация токенов в каждом предложении начиналась заново:\n",
    "    for sent_id, parsed_sent in enumerate(parsed_sents):\n",
    "        token_ids_map = {\n",
    "            token[\"id\"]: token_id for token_id, token in enumerate(parsed_sent)\n",
    "        }\n",
    "        for token_id, token in enumerate(parsed_sent):\n",
    "            parsed_sents[sent_id][token_id][\"id\"] = token_ids_map[token[\"id\"]]\n",
    "            parsed_sents[sent_id][token_id][\"head\"] = token_ids_map[\n",
    "                token[\"head\"]\n",
    "            ]\n",
    "\n",
    "    return parsed_sents\n",
    "\n",
    "def serialize_parse(\n",
    "    parse: spacy.tokens.doc.Doc, orig_string: str\n",
    ") -> dict:\n",
    "    parse_result = parse.to_json()\n",
    "\n",
    "    # Добавить оригинальный текст токена:\n",
    "    for i in range(len(parse_result[\"tokens\"])):\n",
    "        parse_result[\"tokens\"][i][\"text\"] = orig_string[\n",
    "            parse_result[\"tokens\"][i][\"start\"]:parse_result[\"tokens\"][i][\"end\"]\n",
    "        ]\n",
    "\n",
    "    return parse_result\n",
    "\n",
    "NLP = spacy.load(\"ru_core_news_lg\")\n",
    "\n",
    "def parse(text: str) -> list[list[dict[str, Union[str, int]]]]:\n",
    "    result = process_text_parse(serialize_parse(NLP(text), text))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9516b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "ORIG_DATASET = pd.read_excel(\"../data_input/EgeEvalDataset.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d8fe116",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data_input/data_dict_processed.json\", 'r', encoding=\"utf8\") as inp:\n",
    "    data_dict_processed = json.load(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44b3d956",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_ITER = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "01d9ef5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BartDG 166\n",
      "BartDG_PM 167\n",
      "BartDG_ANPM 167\n",
      "MuSeRC_GPT3 159\n",
      "MuSeRC_T5 89\n",
      "RuRace_GPT3 156\n",
      "RuRace_T5 160\n",
      "Deepseek 165\n",
      "ChatGPT4o 166\n",
      "true_distractors 166\n"
     ]
    }
   ],
   "source": [
    "for key, val in data_dict_processed.items():\n",
    "    print(key, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "699cd67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_LEN = 84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ab3ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "seeds = random.sample(list(range(1, 1000000)), N_ITER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "60c9fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 9971/10001 [00:04<00:00, 2089.59it/s]"
     ]
    }
   ],
   "source": [
    "subsample_lex_estimates = []\n",
    "\n",
    "progr = tqdm(total = len(data_dict_processed) * N_ITER + 1)\n",
    "\n",
    "for key, val in data_dict_processed.items():\n",
    "    lex_row = {\n",
    "        \"source\": key,\n",
    "        **get_lex_features(val)\n",
    "    }\n",
    "\n",
    "    sample_estimates = defaultdict(list)\n",
    "    for i in range(N_ITER):\n",
    "        random.seed(seeds[i])\n",
    "        sample = random.sample(val, k=SAMPLE_LEN)\n",
    "        lex_metrics = get_lex_features(sample)\n",
    "        for name, metric_val in lex_metrics.items():\n",
    "            sample_estimates[name].append(metric_val)\n",
    "        \n",
    "        progr.update()\n",
    "    \n",
    "    for name, metric in sample_estimates.items():\n",
    "        metric = pd.Series(metric)\n",
    "        lex_row[f\"{name} Ср. Сэмпл.\"] = metric.mean()\n",
    "        lex_row[f\"{name} Стд. Сэмпл.\"] = metric.std()\n",
    "    \n",
    "    subsample_lex_estimates.append(lex_row)\n",
    "\n",
    "progr.update()\n",
    "\n",
    "subsample_lex_estimates = pd.DataFrame(\n",
    "    subsample_lex_estimates\n",
    ").set_index(\"source\").sort_index(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c55d961d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LD</th>\n",
       "      <th>LD Ср. Сэмпл.</th>\n",
       "      <th>LD Стд. Сэмпл.</th>\n",
       "      <th>LTR</th>\n",
       "      <th>LTR Ср. Сэмпл.</th>\n",
       "      <th>LTR Стд. Сэмпл.</th>\n",
       "      <th>TTR</th>\n",
       "      <th>TTR Ср. Сэмпл.</th>\n",
       "      <th>TTR Стд. Сэмпл.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BartDG</th>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.733909</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>0.462766</td>\n",
       "      <td>0.567703</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>0.706393</td>\n",
       "      <td>0.014506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BartDG_PM</th>\n",
       "      <td>0.680290</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.397495</td>\n",
       "      <td>0.510241</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.543177</td>\n",
       "      <td>0.642551</td>\n",
       "      <td>0.015135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BartDG_ANPM</th>\n",
       "      <td>0.679284</td>\n",
       "      <td>0.679340</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.397798</td>\n",
       "      <td>0.502025</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.543014</td>\n",
       "      <td>0.636640</td>\n",
       "      <td>0.015573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuSeRC_GPT3</th>\n",
       "      <td>0.641240</td>\n",
       "      <td>0.641541</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.479142</td>\n",
       "      <td>0.571519</td>\n",
       "      <td>0.017450</td>\n",
       "      <td>0.557807</td>\n",
       "      <td>0.650877</td>\n",
       "      <td>0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuSeRC_T5</th>\n",
       "      <td>0.664099</td>\n",
       "      <td>0.664171</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.519542</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.587710</td>\n",
       "      <td>0.009351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuRace_GPT3</th>\n",
       "      <td>0.630984</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.416223</td>\n",
       "      <td>0.511987</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.503989</td>\n",
       "      <td>0.595825</td>\n",
       "      <td>0.014070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuRace_T5</th>\n",
       "      <td>0.680805</td>\n",
       "      <td>0.680647</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.559920</td>\n",
       "      <td>0.014250</td>\n",
       "      <td>0.569375</td>\n",
       "      <td>0.654977</td>\n",
       "      <td>0.015335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deepseek</th>\n",
       "      <td>0.689912</td>\n",
       "      <td>0.689701</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.491864</td>\n",
       "      <td>0.584307</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.620642</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>0.010040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChatGPT4o</th>\n",
       "      <td>0.718770</td>\n",
       "      <td>0.718537</td>\n",
       "      <td>0.009037</td>\n",
       "      <td>0.516336</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>0.657912</td>\n",
       "      <td>0.730415</td>\n",
       "      <td>0.010971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_distractors</th>\n",
       "      <td>0.697802</td>\n",
       "      <td>0.697711</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.514486</td>\n",
       "      <td>0.608871</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.645854</td>\n",
       "      <td>0.714291</td>\n",
       "      <td>0.011353</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        LD  LD Ср. Сэмпл.  LD Стд. Сэмпл.       LTR  \\\n",
       "source                                                                \n",
       "BartDG            0.734043       0.733909        0.011123  0.462766   \n",
       "BartDG_PM         0.680290       0.680919        0.011396  0.397495   \n",
       "BartDG_ANPM       0.679284       0.679340        0.011393  0.397798   \n",
       "MuSeRC_GPT3       0.641240       0.641541        0.012280  0.479142   \n",
       "MuSeRC_T5         0.664099       0.664171        0.004198  0.508475   \n",
       "RuRace_GPT3       0.630984       0.630488        0.009291  0.416223   \n",
       "RuRace_T5         0.680805       0.680647        0.010420  0.461538   \n",
       "Deepseek          0.689912       0.689701        0.007567  0.491864   \n",
       "ChatGPT4o         0.718770       0.718537        0.009037  0.516336   \n",
       "true_distractors  0.697802       0.697711        0.008836  0.514486   \n",
       "\n",
       "                  LTR Ср. Сэмпл.  LTR Стд. Сэмпл.       TTR  TTR Ср. Сэмпл.  \\\n",
       "source                                                                        \n",
       "BartDG                  0.567703         0.014444  0.623100        0.706393   \n",
       "BartDG_PM               0.510241         0.014290  0.543177        0.642551   \n",
       "BartDG_ANPM             0.502025         0.014719  0.543014        0.636640   \n",
       "MuSeRC_GPT3             0.571519         0.017450  0.557807        0.650877   \n",
       "MuSeRC_T5               0.519542         0.008585  0.576271        0.587710   \n",
       "RuRace_GPT3             0.511987         0.013641  0.503989        0.595825   \n",
       "RuRace_T5               0.559920         0.014250  0.569375        0.654977   \n",
       "Deepseek                0.584307         0.010788  0.620642        0.688046   \n",
       "ChatGPT4o               0.622419         0.012764  0.657912        0.730415   \n",
       "true_distractors        0.608871         0.011833  0.645854        0.714291   \n",
       "\n",
       "                  TTR Стд. Сэмпл.  \n",
       "source                             \n",
       "BartDG                   0.014506  \n",
       "BartDG_PM                0.015135  \n",
       "BartDG_ANPM              0.015573  \n",
       "MuSeRC_GPT3              0.018447  \n",
       "MuSeRC_T5                0.009351  \n",
       "RuRace_GPT3              0.014070  \n",
       "RuRace_T5                0.015335  \n",
       "Deepseek                 0.010040  \n",
       "ChatGPT4o                0.010971  \n",
       "true_distractors         0.011353  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample_lex_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86fb7463",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10928it [00:05, 1759.88it/s]                          "
     ]
    }
   ],
   "source": [
    "val = [\n",
    "    parse(i) for i in ORIG_DATASET[\"right_answer\"].values.tolist()\n",
    "]\n",
    "\n",
    "lex_row = {\n",
    "    \"source\": \"right_answer\",\n",
    "    **get_lex_features(val)\n",
    "}\n",
    "\n",
    "SAMPLE_LEN = 23\n",
    "\n",
    "sample_estimates = defaultdict(list)\n",
    "for i in range(N_ITER):\n",
    "    random.seed(seeds[i])\n",
    "    sample = random.sample(val, k=SAMPLE_LEN)\n",
    "    lex_metrics = get_lex_features(sample)\n",
    "    for name, metric_val in lex_metrics.items():\n",
    "        sample_estimates[name].append(metric_val)\n",
    "\n",
    "    progr.update()\n",
    "\n",
    "for name, metric in sample_estimates.items():\n",
    "    metric = pd.Series(metric)\n",
    "    lex_row[f\"{name} Ср. Сэмпл.\"] = metric.mean()\n",
    "    lex_row[f\"{name} Стд. Сэмпл.\"] = metric.std()\n",
    "\n",
    "subsample_lex_estimates.loc[\"right_answer\"] = lex_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7740efbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LD</th>\n",
       "      <th>LD Ср. Сэмпл.</th>\n",
       "      <th>LD Стд. Сэмпл.</th>\n",
       "      <th>LTR</th>\n",
       "      <th>LTR Ср. Сэмпл.</th>\n",
       "      <th>LTR Стд. Сэмпл.</th>\n",
       "      <th>TTR</th>\n",
       "      <th>TTR Ср. Сэмпл.</th>\n",
       "      <th>TTR Стд. Сэмпл.</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BartDG</th>\n",
       "      <td>0.734043</td>\n",
       "      <td>0.733909</td>\n",
       "      <td>0.011123</td>\n",
       "      <td>0.462766</td>\n",
       "      <td>0.567703</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.623100</td>\n",
       "      <td>0.706393</td>\n",
       "      <td>0.014506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BartDG_PM</th>\n",
       "      <td>0.680290</td>\n",
       "      <td>0.680919</td>\n",
       "      <td>0.011396</td>\n",
       "      <td>0.397495</td>\n",
       "      <td>0.510241</td>\n",
       "      <td>0.014290</td>\n",
       "      <td>0.543177</td>\n",
       "      <td>0.642551</td>\n",
       "      <td>0.015135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BartDG_ANPM</th>\n",
       "      <td>0.679284</td>\n",
       "      <td>0.679340</td>\n",
       "      <td>0.011393</td>\n",
       "      <td>0.397798</td>\n",
       "      <td>0.502025</td>\n",
       "      <td>0.014719</td>\n",
       "      <td>0.543014</td>\n",
       "      <td>0.636640</td>\n",
       "      <td>0.015573</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuSeRC_GPT3</th>\n",
       "      <td>0.641240</td>\n",
       "      <td>0.641541</td>\n",
       "      <td>0.012280</td>\n",
       "      <td>0.479142</td>\n",
       "      <td>0.571519</td>\n",
       "      <td>0.017450</td>\n",
       "      <td>0.557807</td>\n",
       "      <td>0.650877</td>\n",
       "      <td>0.018447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MuSeRC_T5</th>\n",
       "      <td>0.664099</td>\n",
       "      <td>0.664171</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.508475</td>\n",
       "      <td>0.519542</td>\n",
       "      <td>0.008585</td>\n",
       "      <td>0.576271</td>\n",
       "      <td>0.587710</td>\n",
       "      <td>0.009351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuRace_GPT3</th>\n",
       "      <td>0.630984</td>\n",
       "      <td>0.630488</td>\n",
       "      <td>0.009291</td>\n",
       "      <td>0.416223</td>\n",
       "      <td>0.511987</td>\n",
       "      <td>0.013641</td>\n",
       "      <td>0.503989</td>\n",
       "      <td>0.595825</td>\n",
       "      <td>0.014070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RuRace_T5</th>\n",
       "      <td>0.680805</td>\n",
       "      <td>0.680647</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>0.461538</td>\n",
       "      <td>0.559920</td>\n",
       "      <td>0.014250</td>\n",
       "      <td>0.569375</td>\n",
       "      <td>0.654977</td>\n",
       "      <td>0.015335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Deepseek</th>\n",
       "      <td>0.689912</td>\n",
       "      <td>0.689701</td>\n",
       "      <td>0.007567</td>\n",
       "      <td>0.491864</td>\n",
       "      <td>0.584307</td>\n",
       "      <td>0.010788</td>\n",
       "      <td>0.620642</td>\n",
       "      <td>0.688046</td>\n",
       "      <td>0.010040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ChatGPT4o</th>\n",
       "      <td>0.718770</td>\n",
       "      <td>0.718537</td>\n",
       "      <td>0.009037</td>\n",
       "      <td>0.516336</td>\n",
       "      <td>0.622419</td>\n",
       "      <td>0.012764</td>\n",
       "      <td>0.657912</td>\n",
       "      <td>0.730415</td>\n",
       "      <td>0.010971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>true_distractors</th>\n",
       "      <td>0.697802</td>\n",
       "      <td>0.697711</td>\n",
       "      <td>0.008836</td>\n",
       "      <td>0.514486</td>\n",
       "      <td>0.608871</td>\n",
       "      <td>0.011833</td>\n",
       "      <td>0.645854</td>\n",
       "      <td>0.714291</td>\n",
       "      <td>0.011353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>right_answer</th>\n",
       "      <td>0.667133</td>\n",
       "      <td>0.667723</td>\n",
       "      <td>0.016389</td>\n",
       "      <td>0.611189</td>\n",
       "      <td>0.710045</td>\n",
       "      <td>0.023065</td>\n",
       "      <td>0.711888</td>\n",
       "      <td>0.782344</td>\n",
       "      <td>0.018850</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        LD  LD Ср. Сэмпл.  LD Стд. Сэмпл.       LTR  \\\n",
       "source                                                                \n",
       "BartDG            0.734043       0.733909        0.011123  0.462766   \n",
       "BartDG_PM         0.680290       0.680919        0.011396  0.397495   \n",
       "BartDG_ANPM       0.679284       0.679340        0.011393  0.397798   \n",
       "MuSeRC_GPT3       0.641240       0.641541        0.012280  0.479142   \n",
       "MuSeRC_T5         0.664099       0.664171        0.004198  0.508475   \n",
       "RuRace_GPT3       0.630984       0.630488        0.009291  0.416223   \n",
       "RuRace_T5         0.680805       0.680647        0.010420  0.461538   \n",
       "Deepseek          0.689912       0.689701        0.007567  0.491864   \n",
       "ChatGPT4o         0.718770       0.718537        0.009037  0.516336   \n",
       "true_distractors  0.697802       0.697711        0.008836  0.514486   \n",
       "right_answer      0.667133       0.667723        0.016389  0.611189   \n",
       "\n",
       "                  LTR Ср. Сэмпл.  LTR Стд. Сэмпл.       TTR  TTR Ср. Сэмпл.  \\\n",
       "source                                                                        \n",
       "BartDG                  0.567703         0.014444  0.623100        0.706393   \n",
       "BartDG_PM               0.510241         0.014290  0.543177        0.642551   \n",
       "BartDG_ANPM             0.502025         0.014719  0.543014        0.636640   \n",
       "MuSeRC_GPT3             0.571519         0.017450  0.557807        0.650877   \n",
       "MuSeRC_T5               0.519542         0.008585  0.576271        0.587710   \n",
       "RuRace_GPT3             0.511987         0.013641  0.503989        0.595825   \n",
       "RuRace_T5               0.559920         0.014250  0.569375        0.654977   \n",
       "Deepseek                0.584307         0.010788  0.620642        0.688046   \n",
       "ChatGPT4o               0.622419         0.012764  0.657912        0.730415   \n",
       "true_distractors        0.608871         0.011833  0.645854        0.714291   \n",
       "right_answer            0.710045         0.023065  0.711888        0.782344   \n",
       "\n",
       "                  TTR Стд. Сэмпл.  \n",
       "source                             \n",
       "BartDG                   0.014506  \n",
       "BartDG_PM                0.015135  \n",
       "BartDG_ANPM              0.015573  \n",
       "MuSeRC_GPT3              0.018447  \n",
       "MuSeRC_T5                0.009351  \n",
       "RuRace_GPT3              0.014070  \n",
       "RuRace_T5                0.015335  \n",
       "Deepseek                 0.010040  \n",
       "ChatGPT4o                0.010971  \n",
       "true_distractors         0.011353  \n",
       "right_answer             0.018850  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11001it [00:20, 1759.88it/s]"
     ]
    }
   ],
   "source": [
    "subsample_lex_estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31976085",
   "metadata": {},
   "outputs": [],
   "source": [
    "subsample_lex_estimates.to_excel(\n",
    "    \"../data_output_table/distractor_metrics/Lex_metrics_subsampled.xlsx\", float_format=\"%.2f\"\n",
    ")\n",
    "subsample_lex_estimates.to_excel(\n",
    "    \"../data_output_table/tables_for_manuscript/Table10.xlsx\", float_format=\"%.2f\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nn_env_042025",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
